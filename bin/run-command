#!/bin/bash
# -----------------------------------------------------------------------------
# Run an application command using the application image
#
# Optional parameters:
#   --environment_variables - a JSON list of environment variables to add to the
#     the container. Each environment variable is an object with the "name" key
#     specifying the name of the environment variable and the "value" key
#     specifying the value of the environment variable.
#     e.g. '[{ "name" : "DB_USER", "value" : "migrator" }]'
#   --task_role_arn - the IAM role ARN that the task should assume. Overrides the
#     task role specified in the task definition.
#
# Positional parameters:
#   app_name (required) - the name of subdirectory of /infra that holds the
#     application's infrastructure code.
#   environment (required) - the name of the application environment (e.g. dev,
#     staging, prod)
#   command (required) - a JSON list representing the command to run
#     e.g. To run the command `db-migrate-up` with no arguments, set
#     command='["db-migrate-up"]'
#     e.g. To run the command `echo "Hello, world"` set
#     command='["echo", "Hello, world"]')
# -----------------------------------------------------------------------------
set -euo pipefail

# Parse optional parameters
environment_variables=""
task_role_arn=""
while :; do
  case $1 in
    --environment-variables)
      environment_variables=$2
      shift 2
      ;;
    --task-role-arn)
      task_role_arn=$2
      shift 2
      ;;
    *)
      break
      ;;
  esac
done

app_name="$1"
environment="$2"
command="$3"

echo "==============="
echo "Running command"
echo "==============="
echo "Input parameters"
echo "  app_name=$app_name"
echo "  environment=$environment"
echo "  command=$command"
echo "  environment_variables=${environment_variables:-}"
echo "  task_role_arn=${task_role_arn:-}"
echo

# Use the same cluster, task definition, and network configuration that the application service uses
cluster_name=$(terraform -chdir="infra/$app_name/service" output -raw service_cluster_name)
service_name=$(terraform -chdir="infra/$app_name/service" output -raw service_name)

# Get the log group and log stream prefix so that we can print out the ECS task's logs after running the task
log_group=$(terraform -chdir="infra/$app_name/service" output -raw application_log_group)
log_stream_prefix=$(terraform -chdir="infra/$app_name/service" output -raw application_log_stream_prefix)

service_task_definition_arn=$(aws ecs describe-services --no-cli-pager --cluster "$cluster_name" --services "$service_name" --query "services[0].taskDefinition" --output text)
# For subsequent commands, use the task definition family rather than the service's task definition ARN
# because in the case of migrations, we'll deploy a new task definition revision before updating the
# service, so the service will be using an old revision, but we want to use the latest revision.
task_definition_family=$(aws ecs describe-task-definition --no-cli-pager --task-definition "$service_task_definition_arn" --query "taskDefinition.family" --output text)

network_config=$(aws ecs describe-services --no-cli-pager --cluster "$cluster_name" --services "$service_name" --query "services[0].networkConfiguration")
current_region=$(./bin/current-region)
aws_user_id=$(aws sts get-caller-identity --no-cli-pager --query UserId --output text)

container_name=$(aws ecs describe-task-definition --task-definition "$task_definition_family" --query "taskDefinition.containerDefinitions[0].name" --output text)

overrides=$(cat << EOF
{
  "containerOverrides": [
    {
      "name": "$container_name",
      "command": $command
    }
  ]
}
EOF
)

if [ -n "$environment_variables" ]; then
  overrides=$(echo "$overrides" | jq ".containerOverrides[0].environment |= $environment_variables")
fi

if [ -n "$task_role_arn" ]; then
  overrides=$(echo "$overrides" | jq ".taskRoleArn |= \"$task_role_arn\"")
fi

task_start_time=$(date +%s)
task_start_time_millis=$((task_start_time * 1000))

aws_args=(
  ecs run-task
  --region="$current_region"
  --cluster="$cluster_name"
  --task-definition="$task_definition_family"
  --started-by="$aws_user_id"
  --launch-type=FARGATE
  --platform-version=1.4.0
  --network-configuration "$network_config"
  --overrides "$overrides"
)
echo "::group::Running AWS CLI command"
printf " ... %s\n" "${aws_args[@]}"
task_arn=$(aws --no-cli-pager "${aws_args[@]}" --query "tasks[0].taskArn" --output text)
echo "::endgroup::"
echo

# Get the task id by extracting the substring after the last '/' since the task ARN is of
# the form "arn:aws:ecs:<region>:<account id>:task/<cluster name>/<task id>"
ecs_task_id=$(basename "$task_arn")

# The log stream has the format "prefix-name/container-name/ecs-task-id"
# See https://docs.aws.amazon.com/AmazonECS/latest/userguide/using_awslogs.html
log_stream="$log_stream_prefix/$container_name/$ecs_task_id"

# Wait for log stream to be created before fetching the logs.
# The reason we don't use the `aws ecs wait tasks-running` command is because
# that command can fail on short-lived tasks. In particular, the command polls
# every 6 seconds with describe-tasks until tasks[].lastStatus is RUNNING. A
# task that completes quickly can go from PENDING to STOPPED, causing the wait
# command to error out.
echo "Waiting for log stream to be created"
echo "  task_arn=$task_arn"
echo "  task_id=$ecs_task_id"
echo "  log_stream=$log_stream"

num_retries_waiting_for_logs=0
while true; do
  num_retries_waiting_for_logs=$((num_retries_waiting_for_logs+1))
  if [ $num_retries_waiting_for_logs -eq 20 ]; then
    echo "Timing out task $ecs_task_id waiting for logs"
    exit 1
  fi
  is_log_stream_created=$(aws logs describe-log-streams --no-cli-pager --log-group-name "$log_group" --log-stream-name-prefix "$log_stream" | jq -r '.logStreams | length')
  if [ "$is_log_stream_created" == "1" ]; then
    break
  fi
  sleep 5
  echo -n "."
done
echo
echo

# Tail logs until task stops using a loop that polls for new logs.
# The reason why we don't use `aws logs tail` is because that command is meant
# for interactive use. In particular, it will wait forever for new logs, even
# after a task stops, until the user hits Ctrl+C. And the reason why we don't
# wait until the task completes first before fetching logs is so that we can
# show logs in near real-time, which can be useful for long running tasks.
echo "::group::Tailing logs until task stops"
echo "  log_group=$log_group"
echo "  log_stream=$log_stream"
echo "  task_start_time_millis=$task_start_time_millis"
# Initialize the logs start time filter to the time we started the task
logs_start_time_millis=$task_start_time_millis
while true; do
  # Print logs with human readable timestamps by fetching the log events as JSON
  # then transforming them afterwards using jq
  log_events=$(aws logs get-log-events \
    --no-cli-pager \
    --log-group-name "$log_group" \
    --log-stream-name "$log_stream" \
    --start-time "$logs_start_time_millis" \
    --start-from-head \
    --no-paginate \
    --output json)
  # Divide timestamp by 1000 since AWS timestamps are in milliseconds
  echo "$log_events" | jq -r '.events[] | ((.timestamp / 1000 | strftime("%Y-%m-%d %H:%M:%S")) + "\t" + .message)'

  # If the task stopped, then stop tailing logs
  last_task_status=$(aws ecs describe-tasks --cluster "$cluster_name" --tasks "$task_arn" --query "tasks[0].containers[?name=='$container_name'].lastStatus" --output text)
  if [ "$last_task_status" = "STOPPED" ]; then
    break
  fi

  # If there were new logs printed, then update the logs start time filter
  # to be the last log's timestamp + 1
  last_log_timestamp=$(echo "$log_events" | jq -r '.events[-1].timestamp' )
  if [ "$last_log_timestamp" != "null" ]; then
    logs_start_time_millis=$((last_log_timestamp + 1))
  fi

  # Give the application a moment to generate more logs before fetching again
  sleep 1
done
echo "::endgroup::"
echo

container_exit_code=$(
  aws ecs describe-tasks \
  --cluster "$cluster_name" \
  --tasks "$task_arn" \
  --query "tasks[0].containers[?name=='$container_name'].exitCode" \
  --output text
)

if [[ "$container_exit_code" == "null" || "$container_exit_code" != "0" ]]; then
  echo "Task failed" >&2
  # Although we could avoid extra calls to AWS CLI if we just got the full JSON response from
  # `aws ecs describe-tasks` and parsed it with jq, we are trying to avoid unnecessary dependencies.
  container_status=$(aws ecs describe-tasks --cluster "$cluster_name" --tasks "$task_arn" --query "tasks[0].containers[?name=='$container_name'].[lastStatus,exitCode,reason]" --output text)
  task_status=$(aws ecs describe-tasks --cluster "$cluster_name" --tasks "$task_arn" --query "tasks[0].[lastStatus,stopCode,stoppedAt,stoppedReason]" --output text)

  echo "Container status (lastStatus, exitCode, reason): $container_status" >&2
  echo "Task status (lastStatus, stopCode, stoppedAt, stoppedReason): $task_status" >&2
  exit 1
fi
